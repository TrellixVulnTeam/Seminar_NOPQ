{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this implementation of the Decision Tree we made use of the following source code, and improved it to make it faster:\n",
    "# The code is taken from a Youtube tutorial, given by Josh Gordon. The code he uses in the tutorial can be found on\n",
    "# https://github.com/random-forests/tutorials/blob/master/decision_tree.py\n",
    "# Last accessed on 22-06-2020. \n",
    "\n",
    "# We changed this code to be able to add the differential privacy\n",
    "# The theory of adding privacy is obtained from the following papers:\n",
    "# 1. S. Fletcher, MD Z. Islam, 'Decision Tree Classification with Differential Privacy: A Survey'\n",
    "# The paper can be found on https://arxiv.org/pdf/1611.01919.pdf, Last accessed on 22-06-2020. \n",
    "\n",
    "# 2. G. Jgannathan, K. Pillaipakkamnatt, R. N. Wright, 'A Practical Differentially Private Random Decision Tree Classifier'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "# This target is the name of the column that contains the label. In the SPECT_Heart dataset this is the 'Diagnosis' column.\n",
    "target = 'Diagnosis'\n",
    "\n",
    "def prepare_data(location_training_data, location_testing_data=None):\n",
    "    # Define the headings to be used\n",
    "    headings = ['Diagnosis','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22']\n",
    "\n",
    "    # Read in the official training and testing data separately\n",
    "    df = pd.read_csv(location_training_data, names=headings)\n",
    "\n",
    "    if location_testing_data is not None:\n",
    "        data_test = pd.read_csv(location_testing_data, names=headings, skiprows=1)\n",
    "\n",
    "        # Combine both data sets into one data set\n",
    "        df = df.append(data_test)\n",
    "\n",
    "    # Apply some pre-processing\n",
    "    # For an attribute that contains only numerical values do:\n",
    "    # df[attribute_name] = df[attribute_name].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    # For an attribute that contains only categorical values do:\n",
    "    # df[attribute_name] = df[attribute_name].astype('category').str.strip()\n",
    "\n",
    "    df['Diagnosis'] = df['Diagnosis'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F1'] = df['F1'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F2'] = df['F2'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F3'] = df['F3'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F4'] = df['F4'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F5'] = df['F5'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F6'] = df['F6'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F7'] = df['F7'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F8'] = df['F8'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F9'] = df['F9'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F10'] = df['F10'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F11'] = df['F11'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F12'] = df['F12'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F13'] = df['F13'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F14'] = df['F14'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F15'] = df['F15'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F16'] = df['F16'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F17'] = df['F17'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F18'] = df['F18'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F19'] = df['F19'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F20'] = df['F20'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F21'] = df['F21'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "    df['F22'] = df['F22'].astype('int').apply(pd.to_numeric, downcast=\"unsigned\")\n",
    "\n",
    "    # Convert every '?' to NaN, so Panda's built-in functions can be used\n",
    "    df = df.where(df != '?')\n",
    "\n",
    "    # Try to fill missing values with the mean (this only works for numerical attributes)\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    # Get the number of records in the data set\n",
    "    n_records_before = df.shape[0]\n",
    "\n",
    "    # If values are still missing (they must be categorical attributes), drop the rows with missing data\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Get the number of records in the data set\n",
    "    n_records_after = df.shape[0]\n",
    "\n",
    "    # Print how many records containing NaN values got dropped\n",
    "    n_records_dropped = n_records_before - n_records_after\n",
    "    print(n_records_dropped, \"records were dropped due to missing values.\")\n",
    "    print(\"This is\", round(n_records_dropped / n_records_before * 100, 1), \"% of the entire data set.\")\n",
    "    print(\"The resulting data set contains\", n_records_after, \"records.\")\n",
    "\n",
    "    # Reset the indices\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def cross_validation_train_test_split(data_set, buckets_location, bucket_number):\n",
    "    # Read all the bucket indices for the specified bucket number from the provided CSV file\n",
    "    bucket_indices = pd.read_csv(buckets_location).iloc[bucket_number].dropna().values\n",
    "\n",
    "    # Split the entire data set into testing and training data\n",
    "    data_test = data_set.iloc[bucket_indices]\n",
    "    data_train = data_set.drop(bucket_indices, axis='index')\n",
    "\n",
    "    # Reset the indices of the data\n",
    "    data_test.reset_index(drop=True, inplace=True)\n",
    "    data_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data_train, data_test\n",
    "\n",
    "\n",
    "# Load and prepare the training and testing data\n",
    "# When there are both a training file and a test file pass both as parameters, otherwise pass the whole file as training_data.\n",
    "\n",
    "# Depending on where the datasets are stored it might be that the path is not correct, but the suffix is correct for the SPECT_Heart dataset.\n",
    "\n",
    "all_data = prepare_data(location_training_data='../datasets/SPECT_Heart/SPECT.train', location_testing_data='../datasets/SPECT_Heart/SPECT.test')\n",
    "\n",
    "# Define the location where the buckets are stored\n",
    "buckets_loc = '../datasets/SPECT_Heart/buckets_SPEC.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    # A class to return the Leaf node that contains the label.\n",
    "    def __init__(self, dataset, target):\n",
    "        self.predictions = dataset[target].value_counts()\n",
    "\n",
    "\n",
    "class Decision_Node:\n",
    "    # A class to return the Decision node, that contains a question and 2 branches, based on this question. \n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "# Function to determine if a value is numeric. \n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    # Class that represents the question, it contains the attribute (column) and the value of that attribute (value)\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    # Function to check if the example row matches the question, to determine the branch. \n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    # The Decision Tree classifier class. It takes as input a parameter epsilon, which is optional.\n",
    "    # Epsilon must be greater or equal then 0, so for example 1*10^-10. \n",
    "    def __init__(self, e=None):\n",
    "        self._e = e\n",
    "        return\n",
    "    \n",
    "    def laplace(self, mean, scale):\n",
    "        # Sample the Laplace distribution to generate some noise as explained in the paper\n",
    "        \n",
    "        return np.random.laplace(loc=mean, scale=scale)\n",
    "\n",
    "    def gini(self, dataset):\n",
    "        # Return Gini index, as explained in the paper\n",
    "        \n",
    "        # No privacy, so the normal variant\n",
    "        if self._e == None:\n",
    "            return 1 - dataset[self._target].value_counts().div(dataset.shape[0]).pow(2).sum()\n",
    "        \n",
    "        # In this case a value for epsilon is entered. \n",
    "        \n",
    "        # Compute the number of attributes that there is left, as we drop the attribute when we\n",
    "        # found a question, and the data is binary the number of attributes is equal to the number\n",
    "        # of columns in the dataset - 1, because we don't count the label. \n",
    "        n_attributes = dataset.shape[1] - 1\n",
    "        \n",
    "        # Compute the scale of the laplacian noise based on the epsilon value, number of attributes\n",
    "        # and the depth of the tree, as explained in the paper.\n",
    "        scale = 1 / (self._e / (n_attributes * (n_attributes+1)))\n",
    "        \n",
    "        # Compute the counts of the labels and add the noise to these counts. \n",
    "        noisy_label_counts = dataset[self._target].value_counts().add(self.laplace(0, scale))\n",
    "\n",
    "        # The noise can be negative, when this is the case we set the noise to be equal to 0.0001, such that is is almost 0.\n",
    "        noisy_label_counts.loc[noisy_label_counts < 0] = 0.0001\n",
    "        \n",
    "        # Compute the sum of the noisy labels\n",
    "        noisy_sum = noisy_label_counts.sum()\n",
    "\n",
    "        # Prevent division by zero with the if statement\n",
    "        if noisy_sum > 0:\n",
    "            noisy_label_counts = noisy_label_counts.div(noisy_sum)\n",
    "  \n",
    "        # Compute the impurity of the dataset. \n",
    "        impurity = 1 - noisy_label_counts.pow(2).sum()\n",
    "         \n",
    "        return impurity\n",
    "\n",
    "    # Compute the information gain as explained in the paper.\n",
    "    def info_gain(self, left, right, current_uncertainty):\n",
    "        p = (float(left.shape[0]) / float(left.shape[0] + right.shape[0]))\n",
    "        return current_uncertainty - (p * self.gini(left)) - ((1 - p) * self.gini(right))\n",
    "\n",
    "    # Function to partition the data into the true_branch and the false_branch.\n",
    "    # The data is splitted based on the question.\n",
    "    # equal or not equal to the question value when the attribute is categorical\n",
    "    # greater/equal or smaller than the question value when the attribute is numerical. \n",
    "    def partition(self, dataset, question):\n",
    "\n",
    "        if dataset[question.column].dtype == 'object':\n",
    "            true_branch = dataset.loc[dataset[question.column] == question.value]\n",
    "            false_branch = dataset.loc[dataset[question.column] != question.value]\n",
    "        else: \n",
    "            true_branch = dataset.loc[dataset[question.column] >= question.value]\n",
    "            false_branch = dataset.loc[dataset[question.column] < question.value]\n",
    "        \n",
    "        # Return the true and false branch but drop the column we used to split the data on.\n",
    "        return true_branch.drop(question.column, axis='columns'), false_branch.drop(question.column, axis='columns')\n",
    "\n",
    "    # Function to find the best question to split the data on. \n",
    "    def find_best_split(self, feature, dataset, current_uncertainty):\n",
    "        \n",
    "        # Take one of the attributes\n",
    "        feature_values = feature.unique()\n",
    "\n",
    "        # Create an empty series object, with the size of the number of attribute values for that attribute. \n",
    "        gain_s = pd.Series(0, index=feature_values)\n",
    "\n",
    "        # For all the possible values of the attribute, \n",
    "        # create a question using that attribute value,\n",
    "        # partitite the dataset based on this question,\n",
    "        # compute the information gain for this split,\n",
    "        # store the information gains,\n",
    "        # return the question with the highest information gain,\n",
    "        # and return also the information gain itself. \n",
    "        for value in feature_values:\n",
    "            question = Question(feature.name, value)\n",
    "            true_branch, false_branch = self.partition(dataset, question)\n",
    "\n",
    "            if true_branch.shape[0] == 0 or false_branch.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            gain_s.loc[value] = self.info_gain(true_branch, false_branch, current_uncertainty)\n",
    "\n",
    "        return pd.Series([gain_s.max(), gain_s.idxmax()], index=['gini', 'question'])\n",
    "\n",
    "    def build_tree(self, dataset, target):\n",
    "        # This function computes the subtrees for 1 node, based on the best question.\n",
    "        \n",
    "        self._target = target\n",
    "        \n",
    "        # Compute the best question for all the possible attributes\n",
    "        # So per attribute 1 best question left.\n",
    "        feature_gains = dataset.drop(self._target, axis='columns').apply(self.find_best_split, axis='index', args=[dataset, self.gini(dataset)])\n",
    "\n",
    "        # Take the best question of all the possible attributes\n",
    "        # So 1 question left\n",
    "        best_feature = feature_gains.loc['gini'].astype('float').idxmax()\n",
    "        # Get the best gain, of splitting the dataset on this question\n",
    "        gain = feature_gains[best_feature]['gini']\n",
    "        # Get the value of the question itself\n",
    "        question_value = feature_gains[best_feature]['question']\n",
    "        \n",
    "        # Create a question object\n",
    "        question = Question(best_feature, question_value)\n",
    "        \n",
    "        # If we don't gain anything for the best possible split we can stop and return the label.\n",
    "        if gain == 0:\n",
    "            return Leaf(dataset, self._target)\n",
    "\n",
    "        # If we do gain something for this partition, compute the true and false branch again. \n",
    "        true_branch, false_branch = self.partition(dataset, question)\n",
    "        \n",
    "        # Recursively compute the rest of the tree, by calling build_tree with the true and false branch. \n",
    "        tb = self.build_tree(true_branch, self._target)\n",
    "        fb = self.build_tree(false_branch, self._target)\n",
    "\n",
    "        # Return the tree in a particular format. \n",
    "        return Decision_Node(question, tb, fb)\n",
    "\n",
    "    # A function to classify the data, when the training of the algorithm is completed.\n",
    "    # This function takes an instance (row) of the dataset and a (sub)tree (node).\n",
    "    # Then it compares the attribute in the row with the question, to determine if\n",
    "    # the algorithm should take the true or false branch. \n",
    "    def classify(self, row, node):\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, Leaf):\n",
    "            return node.predictions\n",
    "\n",
    "        if node.question.match(row):\n",
    "            return self.classify(row, node.true_branch)\n",
    "        else:\n",
    "            return self.classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# This code might look very long and complicated, but is actually pretty straightforward \n",
    "# and a repitition of the same testcase, with a different value.\n",
    "\n",
    "# We do 10-fold crossvalidation so we loop over our testcases 10 times, therefore the value r = 10\n",
    "\n",
    "r = 10\n",
    "\n",
    "# Create variables to store / compute the total accuracy over the 10 folds. \n",
    "accuracy_nn = 0\n",
    "accuracy_1 = 0\n",
    "accuracy_075 = 0\n",
    "accuracy_050 = 0\n",
    "accuracy_025 = 0\n",
    "accuracy_010 = 0\n",
    "accuracy_005 = 0\n",
    "accuracy_001 = 0\n",
    "accuracy_0005 = 0\n",
    "accuracy_0001 = 0\n",
    "accuracy_0 = 0\n",
    "\n",
    "# instantiate the tree object\n",
    "tree = None\n",
    "\n",
    "# function to classify an instance of the dataset with the tree.\n",
    "def predict(row):\n",
    "        return classifier.classify(row, tree).index[0]\n",
    "\n",
    "# Loop over the test-cases r times (r = 10, so 10-fold cross-validation)\n",
    "for i in range(r):\n",
    "    print()\n",
    "    \n",
    "    # Retrieve the training and testing data according to a specific bucket number (starts from 0)\n",
    "    # Since we need a different bucket for every fold we set the bucket number equal to the loop counter.\n",
    "    training_data, testing_data = cross_validation_train_test_split(all_data, buckets_location=buckets_loc, bucket_number=i)\n",
    "    #---------------------------------------------------\n",
    "    # A value to compute the runtime of this testcase. \n",
    "    ts = time()\n",
    "    # Create an instance of the Decision Tree object\n",
    "    classifier = DecisionTree()\n",
    "    # Train the Decision Tree using the training data.\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    # Make the predicions for the whole testing dataset at once\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    # Compute the accuracy of the classification by checking the number of \n",
    "    # mismatches between the predictions and actual classification. \n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    # Increase the total accuracy to compute the average. \n",
    "    accuracy_nn += accuracy\n",
    "    # A value to compute the runtime of this testcase\n",
    "    te = time()\n",
    "    # Print the accuracy of this testcase and the runtime. \n",
    "    print(\"No noise:       \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    # The rest of the for-loop works the same as the above, but it\n",
    "    # uses the epsilon values as described in the paper. \n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(1)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_1 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 1.000:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.75)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_075 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.750:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    classifier = DecisionTree(0.5)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "    \n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_050 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.500:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.25)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "    \n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_025 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.250:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.1)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "    \n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_010 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.100:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.05)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "    \n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_005 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.050:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.01)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_001 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.010:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.005)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_0005 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.005:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.001)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_0001 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.001:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "    #---------------------------------------------------\n",
    "    ts = time()\n",
    "    classifier = DecisionTree(0.0000000001)\n",
    "    tree = classifier.build_tree(training_data, target)\n",
    "\n",
    "    predictions = testing_data.apply(predict, axis='columns')\n",
    "    accuracy = accuracy_score(pd.DataFrame(testing_data, columns=[target]), pd.DataFrame(predictions, columns=[target]))\n",
    "    accuracy_0 += accuracy\n",
    "    te = time()\n",
    "    print(\"Epsilon 0.000:  \", accuracy, \"Took: \", te-ts, \" seconds\")\n",
    "\n",
    "# Compute and print the average accuracy after 10-fold cross-validation.\n",
    "print()\n",
    "print('Average accuracy - No noise:       ', accuracy_nn/r)\n",
    "print('Average accuracy - Epsilon 1.000:  ', accuracy_1/r)\n",
    "print('Average accuracy - Epsilon 0.750:  ', accuracy_075/r)\n",
    "print('Average accuracy - Epsilon 0.500:  ', accuracy_050/r)\n",
    "print('Average accuracy - Epsilon 0.250:  ', accuracy_025/r)\n",
    "print('Average accuracy - Epsilon 0.100:  ', accuracy_010/r)\n",
    "print('Average accuracy - Epsilon 0.050:  ', accuracy_005/r)\n",
    "print('Average accuracy - Epsilon 0.010:  ', accuracy_001/r)\n",
    "print('Average accuracy - Epsilon 0.005:  ', accuracy_0005/r)\n",
    "print('Average accuracy - Epsilon 0.001:  ', accuracy_0001/r)\n",
    "print('Average accuracy - Epsilon 0.000:  ', accuracy_0/r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
